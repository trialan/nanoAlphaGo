
Collecting 5 trajectories:  20%|â–ˆâ–ˆâ–ˆâ–Œ              | 1/5 [00:01<00:05,  1.39s/it]
Device is mps

Collecting 5 trajectories: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.09it/s]
Device is mps
Device is mps
Device is mps
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
File ~/Documents/code/nanoAlphaGo/train.py:22
[1m     20[22m wandb[38m.[39minit(project[38m='RL Go'[39m, entity[38m='thomasrialan'[39m)
[1m     21[22m [38mfor[39m _ [38min[39m [38mrange[39m(EPOCHS):
---> 22     [43mppo_train(policy_network, value_network, n_loops[38m[49m=10[39m[43m)
[1m     23[22m     t0 [38m=[39m time[38m.[39mtime()
[1m     24[22m     performance [38m=[39m performance_against_random_policy(policy_network,
[1m     25[22m                                                     n_games[38m=10[39m)
File ~/Documents/code/nanoAlphaGo/rl/ppo.py:28, in ppo_train(policy_net, value_net, n_loops)
[1m     26[22m trajectories [38m=[39m collect_trajectories(policy_net, n_trajectories)
[1m     27[22m add_rewards_to_go_to_trajectories(trajectories)
---> 28 advantages [38m=[39m [43mcompute_advantages(trajectories, value_net)
[1m     29[22m update_policy(policy_net, policy_opt, trajectories, advantages)
[1m     30[22m update_value_function(value_net, value_opt, trajectories)
File ~/Documents/code/nanoAlphaGo/rl/utils.py:45, in compute_advantages(trajectories, valueNN)
[1m     42[22m rewards_to_go [38m=[39m trajectory[[38m'rewards_to_go'[39m]
[1m     43[22m states [38m=[39m trajectory[[38m'board_states'[39m]
---> 45 values [38m=[39m [43mvalueNN(states)
[1m     47[22m advantages [38m=[39m []
[1m     48[22m gae [38m=[39m [38m0
File ~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1518, in Module._wrapped_call_impl(self, *args, **kwargs)
[1m   1516[22m     [38mreturn[39m [38mself.[39m_compiled_call_impl([38m*[39margs, [38m**[39mkwargs)  [38m# type: ignore[misc]
[1m   1517[22m [38melse[39m:
-> 1518     [38mreturn[39m [38mself.[39m[43m_call_impl([38m[49m*[39m[43margs, [38m[49m**[39m[43mkwargs)
File ~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1527, in Module._call_impl(self, *args, **kwargs)
[1m   1522[22m [38m# If we don't have any hooks, we want to skip the rest of the logic in
[1m   1523[22m [38m# this function, and just call forward.
[1m   1524[22m [38mif[39m [38mnot[39m ([38mself.[39m_backward_hooks [38mor[39m [38mself.[39m_backward_pre_hooks [38mor[39m [38mself.[39m_forward_hooks [38mor[39m [38mself.[39m_forward_pre_hooks
[1m   1525[22m         [38mor[39m _global_backward_pre_hooks [38mor[39m _global_backward_hooks
[1m   1526[22m         [38mor[39m _global_forward_hooks [38mor[39m _global_forward_pre_hooks):
-> 1527     [38mreturn[39m [43mforward_call([38m[49m*[39m[43margs, [38m[49m**[39m[43mkwargs)
[1m   1529[22m [38mtry[39m:
[1m   1530[22m     result [38m=[39m [38mNone
File ~/Documents/code/nanoAlphaGo/rl/value.py:23, in ValueNN.forward(self, board_tensors_batch)
[1m     22[22m [38mdef[39m [38mforward[39m([38mself[39m, board_tensors_batch):
---> 23     x [38m=[39m nn[38m.[39mfunctional[38m.[39mrelu([38mself.[39m[43mconv1(board_tensors_batch)[49m)
[1m     24[22m     x [38m=[39m nn[38m.[39mfunctional[38m.[39mrelu([38mself.[39mconv2(x))
[1m     25[22m     x [38m=[39m x[38m.[39mview(x[38m.[39msize([38m0[39m), [38m-1[39m)
File ~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1518, in Module._wrapped_call_impl(self, *args, **kwargs)
[1m   1516[22m     [38mreturn[39m [38mself.[39m_compiled_call_impl([38m*[39margs, [38m**[39mkwargs)  [38m# type: ignore[misc]
[1m   1517[22m [38melse[39m:
-> 1518     [38mreturn[39m [38mself.[39m[43m_call_impl([38m[49m*[39m[43margs, [38m[49m**[39m[43mkwargs)
File ~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1527, in Module._call_impl(self, *args, **kwargs)
[1m   1522[22m [38m# If we don't have any hooks, we want to skip the rest of the logic in
[1m   1523[22m [38m# this function, and just call forward.
[1m   1524[22m [38mif[39m [38mnot[39m ([38mself.[39m_backward_hooks [38mor[39m [38mself.[39m_backward_pre_hooks [38mor[39m [38mself.[39m_forward_hooks [38mor[39m [38mself.[39m_forward_pre_hooks
[1m   1525[22m         [38mor[39m _global_backward_pre_hooks [38mor[39m _global_backward_hooks
[1m   1526[22m         [38mor[39m _global_forward_hooks [38mor[39m _global_forward_pre_hooks):
-> 1527     [38mreturn[39m [43mforward_call([38m[49m*[39m[43margs, [38m[49m**[39m[43mkwargs)
[1m   1529[22m [38mtry[39m:
[1m   1530[22m     result [38m=[39m [38mNone
File ~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/conv.py:460, in Conv2d.forward(self, input)
[1m    459[22m [38mdef[39m [38mforward[39m([38mself[39m, [38minput[39m: Tensor) [38m->[39m Tensor:
--> 460     [38mreturn[39m [38mself.[39m[43m_conv_forward([38m[49minput[39m[43m, [38m[49mself.[39m[43mweight, [38m[49mself.[39m[43mbias)
File ~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/conv.py:456, in Conv2d._conv_forward(self, input, weight, bias)
[1m    452[22m [38mif[39m [38mself.[39mpadding_mode [38m!=[39m [38m'zeros'[39m:
[1m    453[22m     [38mreturn[39m F[38m.[39mconv2d(F[38m.[39mpad([38minput[39m, [38mself.[39m_reversed_padding_repeated_twice, mode[38m=self.[39mpadding_mode),
[1m    454[22m                     weight, bias, [38mself.[39mstride,
[1m    455[22m                     _pair([38m0[39m), [38mself.[39mdilation, [38mself.[39mgroups)
--> 456 [38mreturn[39m [43mF[38m[49m.[39m[43mconv2d([38m[49minput[39m[43m, weight, bias, [38m[49mself.[39m[43mstride,
[1m    457[22m [43m                [38m[49mself.[39m[43mpadding, [38m[49mself.[39m[43mdilation, [38m[49mself.[39m[43mgroups)
RuntimeError: Input type (MPSFloatType) and weight type (torch.FloatTensor) should be the same
> /Users/thomasrialan/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/conv.py(456)_conv_forward()
    454                             weight, bias, self.stride,
    455                             _pair(0), self.dilation, self.groups)
--> 456         return F.conv2d(input, weight, bias, self.stride,
    457                         self.padding, self.dilation, self.groups)
